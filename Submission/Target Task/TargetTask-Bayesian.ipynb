{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03bf6e4a",
   "metadata": {
    "id": "lDgGN_5qzrIP"
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf0d5d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUZ9Zz-djo45",
    "outputId": "a34d3480-2065-4b3d-c19b-2a73d8c1862f"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f809e658",
   "metadata": {
    "id": "43XkYne0GXIf"
   },
   "source": [
    "# Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e90a381",
   "metadata": {
    "id": "YBelCxDXGc62"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Path to local data directory\n",
    "data_dir = '/Users/air/Desktop/FinalProject/Data'\n",
    "\n",
    "# Load data\n",
    "\n",
    "X_labeled = np.load(f'{data_dir}/X_labeled.npy')\n",
    "y_labeled = np.load(f'{data_dir}/y_labeled.npy')\n",
    "\n",
    "X_val = np.load(f'{data_dir}/X_val.npy')\n",
    "y_val = np.load(f'{data_dir}/y_val.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e0efda",
   "metadata": {
    "id": "aIEzHSNiEZnU"
   },
   "source": [
    "## Importing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a118cd44",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "BV6oPmsDEgiL",
    "outputId": "b1e28ddb-9611-4734-b136-669133459266"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = \"/Users/air/Desktop/FinalProject/Models/Rot-PretextTask15epochs.h5\"  # specify your path here\n",
    "model = load_model(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a708e8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "noteable": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        9472      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               524416    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,649,092\n",
      "Trainable params: 1,649,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking the changes in Model Architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d0aee7",
   "metadata": {
    "id": "b2Qn8VxCYosW"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bd8f26a",
   "metadata": {
    "id": "pRtCynZBpI9P"
   },
   "outputs": [],
   "source": [
    "# Removing the top layer and addding a new top layer\n",
    "model.pop()\n",
    "model.add(keras.layers.Dense(10, name='dense_3', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "938f6c80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30zca1Vcq1Mo",
    "jupyter": {
     "outputs_hidden": true
    },
    "noteable": {},
    "outputId": "9b879fec-9e0b-4deb-f851-43e6cd62c870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        9472      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               524416    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,649,482\n",
      "Trainable params: 1,649,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking the changes in Model Architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb169d",
   "metadata": {},
   "source": [
    "## Modifying Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92a224a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iU9-UEJ8rS7X",
    "noteable": {},
    "outputId": "aae669ee-0dc4-476c-ebf7-8938055daf20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d True\n",
      "max_pooling2d True\n",
      "conv2d_1 True\n",
      "conv2d_2 True\n",
      "max_pooling2d_1 True\n",
      "conv2d_3 True\n",
      "conv2d_4 True\n",
      "max_pooling2d_2 True\n",
      "flatten True\n",
      "dense True\n",
      "dropout True\n",
      "dense_1 True\n",
      "dropout_1 True\n",
      "dense_3 True\n"
     ]
    }
   ],
   "source": [
    "# See layer.trainbale boolean of each layer\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7bbe45e",
   "metadata": {
    "id": "70p16Vb_ruj2"
   },
   "outputs": [],
   "source": [
    "# Freezing the Convolutional Layers while keeping Dense layers as Trainable\n",
    "for layer in model.layers:\n",
    "    if layer.name in ['dense_3', 'dense_1', 'dense', 'dropout', 'dropout_1']:\n",
    "      layer.trainable=True\n",
    "    else:\n",
    "      layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a608784c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNAXyPxnsDQ0",
    "noteable": {},
    "outputId": "8bd12310-4944-4f98-d313-531db0230269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d False\n",
      "max_pooling2d False\n",
      "conv2d_1 False\n",
      "conv2d_2 False\n",
      "max_pooling2d_1 False\n",
      "conv2d_3 False\n",
      "conv2d_4 False\n",
      "max_pooling2d_2 False\n",
      "flatten False\n",
      "dense True\n",
      "dropout True\n",
      "dense_1 True\n",
      "dropout_1 True\n",
      "dense_3 True\n"
     ]
    }
   ],
   "source": [
    "# Checking if the changes in 'Trainable' status of each layer have taken place\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfb99e7",
   "metadata": {
    "id": "rkfpr6CuZe2I"
   },
   "source": [
    "# Bayesian Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e243898-9126-4acf-b1b7-405207fff6e4",
   "metadata": {
    "noteable": {
     "cell_type": "code"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | learni... |\n",
      "-------------------------------------------------\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 14:33:29.001965: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 11s 243ms/step - loss: 3.5651 - accuracy: 0.1045 - val_loss: 2.3021 - val_accuracy: 0.0994\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 11s 259ms/step - loss: 2.3553 - accuracy: 0.1028 - val_loss: 2.2914 - val_accuracy: 0.1098\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 11s 262ms/step - loss: 2.3039 - accuracy: 0.1107 - val_loss: 2.1804 - val_accuracy: 0.1680\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 12s 265ms/step - loss: 2.2892 - accuracy: 0.1158 - val_loss: 2.1800 - val_accuracy: 0.1770\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 12s 266ms/step - loss: 2.2657 - accuracy: 0.1150 - val_loss: 2.2239 - val_accuracy: 0.1684\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 12s 266ms/step - loss: 2.2803 - accuracy: 0.1137 - val_loss: 2.2781 - val_accuracy: 0.1212\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 12s 267ms/step - loss: 2.3076 - accuracy: 0.1050 - val_loss: 2.3044 - val_accuracy: 0.1008\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 12s 273ms/step - loss: 2.3053 - accuracy: 0.1016 - val_loss: 2.3040 - val_accuracy: 0.1010\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 12s 278ms/step - loss: 2.3053 - accuracy: 0.0972 - val_loss: 2.3061 - val_accuracy: 0.0982\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 12s 277ms/step - loss: 2.3062 - accuracy: 0.0984 - val_loss: 2.3060 - val_accuracy: 0.1014\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-0.1014  \u001b[0m | \u001b[0m232.2    \u001b[0m | \u001b[0m0.07206  \u001b[0m |\n",
      "Epoch 1/10\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 2.3068 - accuracy: 0.0981 - val_loss: 2.3061 - val_accuracy: 0.0990\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 2.3066 - accuracy: 0.0980 - val_loss: 2.3046 - val_accuracy: 0.1024\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 2.3072 - accuracy: 0.0958 - val_loss: 2.3069 - val_accuracy: 0.0976\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 2.3066 - accuracy: 0.0974 - val_loss: 2.3091 - val_accuracy: 0.1024\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 2.3066 - accuracy: 0.0983 - val_loss: 2.3048 - val_accuracy: 0.0990\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 2.3068 - accuracy: 0.0985 - val_loss: 2.3045 - val_accuracy: 0.1008\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 2.3063 - accuracy: 0.1014 - val_loss: 2.3072 - val_accuracy: 0.1026\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 2.3075 - accuracy: 0.0962 - val_loss: 2.3047 - val_accuracy: 0.0994\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 2.3067 - accuracy: 0.0980 - val_loss: 2.3059 - val_accuracy: 0.0982\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 2.3056 - accuracy: 0.1040 - val_loss: 2.3055 - val_accuracy: 0.0976\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-0.0976  \u001b[0m | \u001b[95m32.05    \u001b[0m | \u001b[95m0.0303   \u001b[0m |\n",
      "Epoch 1/10\n",
      "99/99 [==============================] - 13s 129ms/step - loss: 2.3033 - accuracy: 0.0973 - val_loss: 2.3035 - val_accuracy: 0.1024\n",
      "Epoch 2/10\n",
      "99/99 [==============================] - 13s 132ms/step - loss: 2.3033 - accuracy: 0.1003 - val_loss: 2.3032 - val_accuracy: 0.1024\n",
      "Epoch 3/10\n",
      "99/99 [==============================] - 15s 151ms/step - loss: 2.3033 - accuracy: 0.0974 - val_loss: 2.3028 - val_accuracy: 0.1008\n",
      "Epoch 4/10\n",
      "99/99 [==============================] - 16s 159ms/step - loss: 2.3034 - accuracy: 0.0983 - val_loss: 2.3028 - val_accuracy: 0.1008\n",
      "Epoch 5/10\n",
      "99/99 [==============================] - 16s 161ms/step - loss: 2.3031 - accuracy: 0.0995 - val_loss: 2.3030 - val_accuracy: 0.1008\n",
      "Epoch 6/10\n",
      "99/99 [==============================] - 15s 153ms/step - loss: 2.3031 - accuracy: 0.0961 - val_loss: 2.3034 - val_accuracy: 0.0994\n",
      "Epoch 7/10\n",
      "99/99 [==============================] - 15s 152ms/step - loss: 2.3029 - accuracy: 0.1008 - val_loss: 2.3029 - val_accuracy: 0.1024\n",
      "Epoch 8/10\n",
      "99/99 [==============================] - 15s 153ms/step - loss: 2.3032 - accuracy: 0.1054 - val_loss: 2.3034 - val_accuracy: 0.0982\n",
      "Epoch 9/10\n",
      "99/99 [==============================] - 15s 156ms/step - loss: 2.3034 - accuracy: 0.1006 - val_loss: 2.3029 - val_accuracy: 0.0990\n",
      "Epoch 10/10\n",
      "99/99 [==============================] - 16s 163ms/step - loss: 2.3034 - accuracy: 0.0972 - val_loss: 2.3034 - val_accuracy: 0.1024\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-0.1024  \u001b[0m | \u001b[0m102.4    \u001b[0m | \u001b[0m0.009325 \u001b[0m |\n",
      "Epoch 1/10\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 2.3051 - accuracy: 0.0974 - val_loss: 2.3048 - val_accuracy: 0.0990\n",
      "Epoch 2/10\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 2.3054 - accuracy: 0.0955 - val_loss: 2.3040 - val_accuracy: 0.0976\n",
      "Epoch 3/10\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 2.3051 - accuracy: 0.0977 - val_loss: 2.3063 - val_accuracy: 0.0976\n",
      "Epoch 4/10\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 2.3060 - accuracy: 0.0978 - val_loss: 2.3047 - val_accuracy: 0.0994\n",
      "Epoch 5/10\n",
      "83/83 [==============================] - 14s 175ms/step - loss: 2.3044 - accuracy: 0.1005 - val_loss: 2.3033 - val_accuracy: 0.1010\n",
      "Epoch 6/10\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 2.3045 - accuracy: 0.1004 - val_loss: 2.3049 - val_accuracy: 0.1024\n",
      "Epoch 7/10\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 2.3057 - accuracy: 0.0934 - val_loss: 2.3041 - val_accuracy: 0.1024\n",
      "Epoch 8/10\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 2.3042 - accuracy: 0.1026 - val_loss: 2.3043 - val_accuracy: 0.1008\n",
      "Epoch 9/10\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 2.3050 - accuracy: 0.1009 - val_loss: 2.3037 - val_accuracy: 0.1008\n",
      "Epoch 10/10\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 2.3044 - accuracy: 0.0996 - val_loss: 2.3040 - val_accuracy: 0.1014\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-0.1014  \u001b[0m | \u001b[0m121.4    \u001b[0m | \u001b[0m0.03462  \u001b[0m |\n",
      "Epoch 1/10\n",
      "46/46 [==============================] - 14s 313ms/step - loss: 2.3051 - accuracy: 0.0988 - val_loss: 2.3057 - val_accuracy: 0.0994\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 14s 315ms/step - loss: 2.3048 - accuracy: 0.0984 - val_loss: 2.3053 - val_accuracy: 0.1010\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 14s 316ms/step - loss: 2.3071 - accuracy: 0.0979 - val_loss: 2.3041 - val_accuracy: 0.1010\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 14s 314ms/step - loss: 2.3051 - accuracy: 0.0996 - val_loss: 2.3050 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 14s 313ms/step - loss: 2.3059 - accuracy: 0.1025 - val_loss: 2.3065 - val_accuracy: 0.0982\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 14s 312ms/step - loss: 2.3052 - accuracy: 0.1000 - val_loss: 2.3030 - val_accuracy: 0.0990\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 14s 316ms/step - loss: 2.3053 - accuracy: 0.0960 - val_loss: 2.3060 - val_accuracy: 0.0982\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 14s 313ms/step - loss: 2.3055 - accuracy: 0.0985 - val_loss: 2.3038 - val_accuracy: 0.1014\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 14s 310ms/step - loss: 2.3060 - accuracy: 0.1017 - val_loss: 2.3054 - val_accuracy: 0.1024\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 14s 313ms/step - loss: 2.3059 - accuracy: 0.0964 - val_loss: 2.3053 - val_accuracy: 0.1026\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-0.1026  \u001b[0m | \u001b[0m222.4    \u001b[0m | \u001b[0m0.05393  \u001b[0m |\n",
      "Epoch 1/10\n",
      "43/43 [==============================] - 15s 338ms/step - loss: 2.3065 - accuracy: 0.0979 - val_loss: 2.3044 - val_accuracy: 0.0982\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 15s 342ms/step - loss: 2.3046 - accuracy: 0.1032 - val_loss: 2.3044 - val_accuracy: 0.0976\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 16s 384ms/step - loss: 2.3047 - accuracy: 0.1019 - val_loss: 2.3055 - val_accuracy: 0.0976\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 14s 334ms/step - loss: 2.3066 - accuracy: 0.0986 - val_loss: 2.3045 - val_accuracy: 0.1024\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 15s 345ms/step - loss: 2.3052 - accuracy: 0.0963 - val_loss: 2.3074 - val_accuracy: 0.0976\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 14s 338ms/step - loss: 2.3056 - accuracy: 0.0990 - val_loss: 2.3039 - val_accuracy: 0.1024\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 15s 341ms/step - loss: 2.3058 - accuracy: 0.0950 - val_loss: 2.3042 - val_accuracy: 0.0994\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - 14s 330ms/step - loss: 2.3048 - accuracy: 0.1025 - val_loss: 2.3052 - val_accuracy: 0.1008\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - 14s 338ms/step - loss: 2.3051 - accuracy: 0.1086 - val_loss: 2.3051 - val_accuracy: 0.1014\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - 14s 335ms/step - loss: 2.3063 - accuracy: 0.0990 - val_loss: 2.3058 - val_accuracy: 0.1024\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-0.1024  \u001b[0m | \u001b[0m233.2    \u001b[0m | \u001b[0m0.06855  \u001b[0m |\n",
      "Epoch 1/10\n",
      "77/77 [==============================] - 15s 191ms/step - loss: 2.3087 - accuracy: 0.0982 - val_loss: 2.3078 - val_accuracy: 0.1008\n",
      "Epoch 2/10\n",
      "77/77 [==============================] - 15s 192ms/step - loss: 2.3089 - accuracy: 0.0988 - val_loss: 2.3099 - val_accuracy: 0.1008\n",
      "Epoch 3/10\n",
      "77/77 [==============================] - 14s 189ms/step - loss: 2.3074 - accuracy: 0.0991 - val_loss: 2.3083 - val_accuracy: 0.0976\n",
      "Epoch 4/10\n",
      "77/77 [==============================] - 14s 186ms/step - loss: 2.3074 - accuracy: 0.1049 - val_loss: 2.3084 - val_accuracy: 0.1008\n",
      "Epoch 5/10\n",
      "77/77 [==============================] - 15s 190ms/step - loss: 2.3073 - accuracy: 0.1019 - val_loss: 2.3075 - val_accuracy: 0.0990\n",
      "Epoch 6/10\n",
      "77/77 [==============================] - 14s 183ms/step - loss: 2.3087 - accuracy: 0.0984 - val_loss: 2.3074 - val_accuracy: 0.1026\n",
      "Epoch 7/10\n",
      "77/77 [==============================] - 14s 182ms/step - loss: 2.3072 - accuracy: 0.1011 - val_loss: 2.3080 - val_accuracy: 0.0990\n",
      "Epoch 8/10\n",
      "77/77 [==============================] - 14s 185ms/step - loss: 2.3069 - accuracy: 0.0998 - val_loss: 2.3074 - val_accuracy: 0.0990\n",
      "Epoch 9/10\n",
      "77/77 [==============================] - 14s 185ms/step - loss: 2.3080 - accuracy: 0.1035 - val_loss: 2.3083 - val_accuracy: 0.0982\n",
      "Epoch 10/10\n",
      "77/77 [==============================] - 14s 183ms/step - loss: 2.3065 - accuracy: 0.1008 - val_loss: 2.3083 - val_accuracy: 0.0976\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-0.0976  \u001b[0m | \u001b[0m130.1    \u001b[0m | \u001b[0m0.08782  \u001b[0m |\n",
      "Epoch 1/10\n",
      "223/223 [==============================] - 16s 69ms/step - loss: 2.3099 - accuracy: 0.1016 - val_loss: 2.3082 - val_accuracy: 0.1014\n",
      "Epoch 2/10\n",
      "223/223 [==============================] - 16s 70ms/step - loss: 2.3100 - accuracy: 0.0976 - val_loss: 2.3075 - val_accuracy: 0.0976\n",
      "Epoch 3/10\n",
      "223/223 [==============================] - 15s 69ms/step - loss: 2.3078 - accuracy: 0.1013 - val_loss: 2.3121 - val_accuracy: 0.0994\n",
      "Epoch 4/10\n",
      "223/223 [==============================] - 16s 71ms/step - loss: 2.3111 - accuracy: 0.1013 - val_loss: 2.3079 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "223/223 [==============================] - 15s 68ms/step - loss: 2.3092 - accuracy: 0.0974 - val_loss: 2.3134 - val_accuracy: 0.0982\n",
      "Epoch 6/10\n",
      "223/223 [==============================] - 16s 70ms/step - loss: 2.3115 - accuracy: 0.0950 - val_loss: 2.3077 - val_accuracy: 0.1024\n",
      "Epoch 7/10\n",
      "223/223 [==============================] - 16s 70ms/step - loss: 2.3080 - accuracy: 0.1000 - val_loss: 2.3134 - val_accuracy: 0.1024\n",
      "Epoch 8/10\n",
      "223/223 [==============================] - 15s 67ms/step - loss: 2.3086 - accuracy: 0.1045 - val_loss: 2.3074 - val_accuracy: 0.0994\n",
      "Epoch 9/10\n",
      "223/223 [==============================] - 15s 68ms/step - loss: 2.3101 - accuracy: 0.0942 - val_loss: 2.3090 - val_accuracy: 0.0982\n",
      "Epoch 10/10\n",
      "223/223 [==============================] - 15s 66ms/step - loss: 2.3108 - accuracy: 0.0975 - val_loss: 2.3128 - val_accuracy: 0.0982\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-0.0982  \u001b[0m | \u001b[0m45.15    \u001b[0m | \u001b[0m0.06708  \u001b[0m |\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - 14s 328ms/step - loss: 2.3053 - accuracy: 0.1024 - val_loss: 2.3039 - val_accuracy: 0.1024\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 14s 321ms/step - loss: 2.3062 - accuracy: 0.0991 - val_loss: 2.3035 - val_accuracy: 0.1008\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 14s 323ms/step - loss: 2.3057 - accuracy: 0.0986 - val_loss: 2.3035 - val_accuracy: 0.0982\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 14s 320ms/step - loss: 2.3044 - accuracy: 0.1015 - val_loss: 2.3046 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 14s 323ms/step - loss: 2.3049 - accuracy: 0.0983 - val_loss: 2.3042 - val_accuracy: 0.0990\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 15s 334ms/step - loss: 2.3049 - accuracy: 0.0966 - val_loss: 2.3074 - val_accuracy: 0.1026\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 15s 333ms/step - loss: 2.3050 - accuracy: 0.1022 - val_loss: 2.3053 - val_accuracy: 0.1014\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 14s 326ms/step - loss: 2.3057 - accuracy: 0.0966 - val_loss: 2.3039 - val_accuracy: 0.0982\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 14s 326ms/step - loss: 2.3050 - accuracy: 0.1025 - val_loss: 2.3054 - val_accuracy: 0.0990\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 14s 332ms/step - loss: 2.3045 - accuracy: 0.0993 - val_loss: 2.3051 - val_accuracy: 0.0976\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-0.0976  \u001b[0m | \u001b[0m232.3    \u001b[0m | \u001b[0m0.05591  \u001b[0m |\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 15s 143ms/step - loss: 2.3043 - accuracy: 0.0967 - val_loss: 2.3049 - val_accuracy: 0.0982\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 15s 150ms/step - loss: 2.3041 - accuracy: 0.0998 - val_loss: 2.3040 - val_accuracy: 0.1024\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 14s 141ms/step - loss: 2.3046 - accuracy: 0.0953 - val_loss: 2.3034 - val_accuracy: 0.0976\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 15s 145ms/step - loss: 2.3038 - accuracy: 0.1034 - val_loss: 2.3043 - val_accuracy: 0.1024\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 14s 141ms/step - loss: 2.3047 - accuracy: 0.1007 - val_loss: 2.3047 - val_accuracy: 0.0994\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 15s 143ms/step - loss: 2.3046 - accuracy: 0.0990 - val_loss: 2.3040 - val_accuracy: 0.0982\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 15s 143ms/step - loss: 2.3050 - accuracy: 0.1012 - val_loss: 2.3034 - val_accuracy: 0.1024\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 15s 145ms/step - loss: 2.3038 - accuracy: 0.1017 - val_loss: 2.3032 - val_accuracy: 0.1026\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 14s 140ms/step - loss: 2.3038 - accuracy: 0.0988 - val_loss: 2.3033 - val_accuracy: 0.0982\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 15s 143ms/step - loss: 2.3041 - accuracy: 0.1028 - val_loss: 2.3031 - val_accuracy: 0.1026\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-0.1026  \u001b[0m | \u001b[0m99.39    \u001b[0m | \u001b[0m0.01989  \u001b[0m |\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 2.3064 - accuracy: 0.0972 - val_loss: 2.3049 - val_accuracy: 0.1014\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 14s 121ms/step - loss: 2.3052 - accuracy: 0.1038 - val_loss: 2.3073 - val_accuracy: 0.0976\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 14s 119ms/step - loss: 2.3067 - accuracy: 0.1000 - val_loss: 2.3070 - val_accuracy: 0.1014\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 14s 119ms/step - loss: 2.3053 - accuracy: 0.0987 - val_loss: 2.3076 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 14s 120ms/step - loss: 2.3052 - accuracy: 0.0998 - val_loss: 2.3046 - val_accuracy: 0.1026\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 14s 119ms/step - loss: 2.3060 - accuracy: 0.1028 - val_loss: 2.3060 - val_accuracy: 0.1024\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 2.3071 - accuracy: 0.0956 - val_loss: 2.3041 - val_accuracy: 0.1008\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 15s 121ms/step - loss: 2.3055 - accuracy: 0.0981 - val_loss: 2.3046 - val_accuracy: 0.0976\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 14s 121ms/step - loss: 2.3054 - accuracy: 0.0957 - val_loss: 2.3050 - val_accuracy: 0.1010\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 14s 120ms/step - loss: 2.3056 - accuracy: 0.0945 - val_loss: 2.3042 - val_accuracy: 0.0982\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-0.0982  \u001b[0m | \u001b[0m84.21    \u001b[0m | \u001b[0m0.03695  \u001b[0m |\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 14s 576ms/step - loss: 2.3052 - accuracy: 0.1019 - val_loss: 2.3050 - val_accuracy: 0.0994\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 14s 590ms/step - loss: 2.3047 - accuracy: 0.0986 - val_loss: 2.3039 - val_accuracy: 0.1008\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 14s 596ms/step - loss: 2.3043 - accuracy: 0.1011 - val_loss: 2.3065 - val_accuracy: 0.0990\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 14s 578ms/step - loss: 2.3053 - accuracy: 0.0996 - val_loss: 2.3054 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 14s 591ms/step - loss: 2.3055 - accuracy: 0.0982 - val_loss: 2.3044 - val_accuracy: 0.0976\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 14s 591ms/step - loss: 2.3047 - accuracy: 0.1020 - val_loss: 2.3040 - val_accuracy: 0.1026\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 14s 596ms/step - loss: 2.3046 - accuracy: 0.1024 - val_loss: 2.3047 - val_accuracy: 0.1014\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 14s 594ms/step - loss: 2.3048 - accuracy: 0.1003 - val_loss: 2.3057 - val_accuracy: 0.1008\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 14s 611ms/step - loss: 2.3049 - accuracy: 0.0996 - val_loss: 2.3048 - val_accuracy: 0.1014\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 14s 589ms/step - loss: 2.3055 - accuracy: 0.0949 - val_loss: 2.3052 - val_accuracy: 0.0982\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-0.0982  \u001b[0m | \u001b[0m430.4    \u001b[0m | \u001b[0m0.06605  \u001b[0m |\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 15s 149ms/step - loss: 2.3062 - accuracy: 0.0998 - val_loss: 2.3098 - val_accuracy: 0.1010\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 14s 148ms/step - loss: 2.3072 - accuracy: 0.1023 - val_loss: 2.3082 - val_accuracy: 0.1014\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 15s 150ms/step - loss: 2.3100 - accuracy: 0.0956 - val_loss: 2.3043 - val_accuracy: 0.1008\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 14s 145ms/step - loss: 2.3077 - accuracy: 0.1000 - val_loss: 2.3083 - val_accuracy: 0.1008\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 14s 148ms/step - loss: 2.3074 - accuracy: 0.0954 - val_loss: 2.3067 - val_accuracy: 0.0982\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 15s 149ms/step - loss: 2.3067 - accuracy: 0.1007 - val_loss: 2.3084 - val_accuracy: 0.1014\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 15s 151ms/step - loss: 2.3061 - accuracy: 0.0972 - val_loss: 2.3046 - val_accuracy: 0.1026\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 14s 147ms/step - loss: 2.3063 - accuracy: 0.0965 - val_loss: 2.3072 - val_accuracy: 0.1008\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 14s 148ms/step - loss: 2.3075 - accuracy: 0.1028 - val_loss: 2.3089 - val_accuracy: 0.0976\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 15s 150ms/step - loss: 2.3084 - accuracy: 0.0988 - val_loss: 2.3039 - val_accuracy: 0.1010\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-0.101   \u001b[0m | \u001b[0m103.7    \u001b[0m | \u001b[0m0.06292  \u001b[0m |\n",
      "Epoch 1/10\n",
      "137/137 [==============================] - 15s 108ms/step - loss: 2.3103 - accuracy: 0.1046 - val_loss: 2.3070 - val_accuracy: 0.0994\n",
      "Epoch 2/10\n",
      "137/137 [==============================] - 14s 106ms/step - loss: 2.3093 - accuracy: 0.0985 - val_loss: 2.3073 - val_accuracy: 0.1010\n",
      "Epoch 3/10\n",
      "137/137 [==============================] - 14s 105ms/step - loss: 2.3099 - accuracy: 0.0995 - val_loss: 2.3118 - val_accuracy: 0.0994\n",
      "Epoch 4/10\n",
      "137/137 [==============================] - 14s 104ms/step - loss: 2.3098 - accuracy: 0.1000 - val_loss: 2.3117 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "137/137 [==============================] - 15s 106ms/step - loss: 2.3091 - accuracy: 0.0976 - val_loss: 2.3059 - val_accuracy: 0.1026\n",
      "Epoch 6/10\n",
      "137/137 [==============================] - 15s 109ms/step - loss: 2.3081 - accuracy: 0.1004 - val_loss: 2.3085 - val_accuracy: 0.0990\n",
      "Epoch 7/10\n",
      "137/137 [==============================] - 15s 112ms/step - loss: 2.3094 - accuracy: 0.1026 - val_loss: 2.3067 - val_accuracy: 0.0982\n",
      "Epoch 8/10\n",
      "137/137 [==============================] - 15s 107ms/step - loss: 2.3089 - accuracy: 0.0976 - val_loss: 2.3103 - val_accuracy: 0.0990\n",
      "Epoch 9/10\n",
      "137/137 [==============================] - 15s 110ms/step - loss: 2.3100 - accuracy: 0.0961 - val_loss: 2.3057 - val_accuracy: 0.1026\n",
      "Epoch 10/10\n",
      "137/137 [==============================] - 15s 108ms/step - loss: 2.3089 - accuracy: 0.0959 - val_loss: 2.3080 - val_accuracy: 0.1024\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-0.1024  \u001b[0m | \u001b[0m73.31    \u001b[0m | \u001b[0m0.07589  \u001b[0m |\n",
      "Epoch 1/10\n",
      "46/46 [==============================] - 15s 315ms/step - loss: 2.3045 - accuracy: 0.0988 - val_loss: 2.3038 - val_accuracy: 0.0982\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 14s 307ms/step - loss: 2.3030 - accuracy: 0.0971 - val_loss: 2.3031 - val_accuracy: 0.0990\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 14s 311ms/step - loss: 2.3031 - accuracy: 0.0998 - val_loss: 2.3038 - val_accuracy: 0.0982\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 15s 323ms/step - loss: 2.3028 - accuracy: 0.1033 - val_loss: 2.3029 - val_accuracy: 0.0990\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 14s 311ms/step - loss: 2.3033 - accuracy: 0.1034 - val_loss: 2.3038 - val_accuracy: 0.0982\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 14s 314ms/step - loss: 2.3033 - accuracy: 0.1024 - val_loss: 2.3029 - val_accuracy: 0.0982\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 14s 307ms/step - loss: 2.3034 - accuracy: 0.0959 - val_loss: 2.3033 - val_accuracy: 0.0982\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 13s 295ms/step - loss: 2.3030 - accuracy: 0.0989 - val_loss: 2.3033 - val_accuracy: 0.0994\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 14s 301ms/step - loss: 2.3030 - accuracy: 0.1027 - val_loss: 2.3032 - val_accuracy: 0.0982\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 14s 299ms/step - loss: 2.3033 - accuracy: 0.1032 - val_loss: 2.3026 - val_accuracy: 0.1024\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-0.1024  \u001b[0m | \u001b[0m221.9    \u001b[0m | \u001b[0m0.01623  \u001b[0m |\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 14s 644ms/step - loss: 2.3045 - accuracy: 0.0995 - val_loss: 2.3039 - val_accuracy: 0.1024\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 13s 622ms/step - loss: 2.3042 - accuracy: 0.1014 - val_loss: 2.3041 - val_accuracy: 0.0982\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 15s 694ms/step - loss: 2.3033 - accuracy: 0.1021 - val_loss: 2.3034 - val_accuracy: 0.0994\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 16s 733ms/step - loss: 2.3045 - accuracy: 0.1003 - val_loss: 2.3039 - val_accuracy: 0.0990\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 15s 704ms/step - loss: 2.3040 - accuracy: 0.0976 - val_loss: 2.3032 - val_accuracy: 0.1024\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 15s 686ms/step - loss: 2.3040 - accuracy: 0.0972 - val_loss: 2.3037 - val_accuracy: 0.0990\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 15s 680ms/step - loss: 2.3039 - accuracy: 0.0953 - val_loss: 2.3036 - val_accuracy: 0.0994\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 14s 661ms/step - loss: 2.3038 - accuracy: 0.1024 - val_loss: 2.3033 - val_accuracy: 0.1008\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 14s 657ms/step - loss: 2.3041 - accuracy: 0.1011 - val_loss: 2.3031 - val_accuracy: 0.0982\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 14s 661ms/step - loss: 2.3033 - accuracy: 0.0976 - val_loss: 2.3047 - val_accuracy: 0.0982\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-0.0982  \u001b[0m | \u001b[0m458.1    \u001b[0m | \u001b[0m0.04478  \u001b[0m |\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 15s 347ms/step - loss: 2.3039 - accuracy: 0.1017 - val_loss: 2.3035 - val_accuracy: 0.0994\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 16s 379ms/step - loss: 2.3039 - accuracy: 0.0996 - val_loss: 2.3038 - val_accuracy: 0.1008\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 15s 355ms/step - loss: 2.3036 - accuracy: 0.0968 - val_loss: 2.3063 - val_accuracy: 0.1026\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 15s 351ms/step - loss: 2.3044 - accuracy: 0.1001 - val_loss: 2.3031 - val_accuracy: 0.1014\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 15s 353ms/step - loss: 2.3035 - accuracy: 0.0983 - val_loss: 2.3047 - val_accuracy: 0.1024\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 16s 377ms/step - loss: 2.3040 - accuracy: 0.1017 - val_loss: 2.3061 - val_accuracy: 0.0982\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 15s 359ms/step - loss: 2.3044 - accuracy: 0.0989 - val_loss: 2.3044 - val_accuracy: 0.0990\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 15s 350ms/step - loss: 2.3050 - accuracy: 0.0972 - val_loss: 2.3033 - val_accuracy: 0.1024\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 15s 356ms/step - loss: 2.3035 - accuracy: 0.0990 - val_loss: 2.3031 - val_accuracy: 0.1024\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 15s 358ms/step - loss: 2.3046 - accuracy: 0.0962 - val_loss: 2.3033 - val_accuracy: 0.1024\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-0.1024  \u001b[0m | \u001b[0m239.5    \u001b[0m | \u001b[0m0.03527  \u001b[0m |\n",
      "Epoch 1/10\n",
      "31/31 [==============================] - 15s 482ms/step - loss: 2.3044 - accuracy: 0.0993 - val_loss: 2.3053 - val_accuracy: 0.1024\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 15s 482ms/step - loss: 2.3036 - accuracy: 0.1017 - val_loss: 2.3040 - val_accuracy: 0.1024\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 15s 484ms/step - loss: 2.3037 - accuracy: 0.1011 - val_loss: 2.3038 - val_accuracy: 0.1008\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 16s 526ms/step - loss: 2.3036 - accuracy: 0.1045 - val_loss: 2.3043 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 14s 464ms/step - loss: 2.3043 - accuracy: 0.1054 - val_loss: 2.3052 - val_accuracy: 0.1008\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 14s 448ms/step - loss: 2.3041 - accuracy: 0.0993 - val_loss: 2.3032 - val_accuracy: 0.0982\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 14s 451ms/step - loss: 2.3035 - accuracy: 0.0968 - val_loss: 2.3043 - val_accuracy: 0.0994\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 13s 432ms/step - loss: 2.3039 - accuracy: 0.1002 - val_loss: 2.3041 - val_accuracy: 0.1008\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 13s 430ms/step - loss: 2.3045 - accuracy: 0.0973 - val_loss: 2.3040 - val_accuracy: 0.1010\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 14s 449ms/step - loss: 2.3030 - accuracy: 0.0992 - val_loss: 2.3044 - val_accuracy: 0.1024\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-0.1024  \u001b[0m | \u001b[0m324.8    \u001b[0m | \u001b[0m0.03935  \u001b[0m |\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 13s 392ms/step - loss: 2.3073 - accuracy: 0.0975 - val_loss: 2.3044 - val_accuracy: 0.1024\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 13s 388ms/step - loss: 2.3056 - accuracy: 0.0959 - val_loss: 2.3056 - val_accuracy: 0.0982\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 13s 389ms/step - loss: 2.3044 - accuracy: 0.1059 - val_loss: 2.3060 - val_accuracy: 0.1008\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 13s 398ms/step - loss: 2.3047 - accuracy: 0.1032 - val_loss: 2.3044 - val_accuracy: 0.1024\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 14s 419ms/step - loss: 2.3052 - accuracy: 0.1010 - val_loss: 2.3066 - val_accuracy: 0.0982\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 14s 415ms/step - loss: 2.3051 - accuracy: 0.0976 - val_loss: 2.3049 - val_accuracy: 0.0982\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 14s 415ms/step - loss: 2.3052 - accuracy: 0.0980 - val_loss: 2.3055 - val_accuracy: 0.0990\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 14s 403ms/step - loss: 2.3048 - accuracy: 0.0976 - val_loss: 2.3045 - val_accuracy: 0.0982\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 14s 405ms/step - loss: 2.3053 - accuracy: 0.0975 - val_loss: 2.3041 - val_accuracy: 0.1026\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 2.3051 - accuracy: 0.1028 - val_loss: 2.3056 - val_accuracy: 0.1026\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-0.1026  \u001b[0m | \u001b[0m297.5    \u001b[0m | \u001b[0m0.07023  \u001b[0m |\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 14s 144ms/step - loss: 2.3065 - accuracy: 0.0998 - val_loss: 2.3041 - val_accuracy: 0.0994\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 14s 143ms/step - loss: 2.3050 - accuracy: 0.0998 - val_loss: 2.3057 - val_accuracy: 0.0990\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 14s 142ms/step - loss: 2.3052 - accuracy: 0.0974 - val_loss: 2.3058 - val_accuracy: 0.1008\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 14s 138ms/step - loss: 2.3054 - accuracy: 0.0968 - val_loss: 2.3052 - val_accuracy: 0.0994\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 14s 138ms/step - loss: 2.3061 - accuracy: 0.0985 - val_loss: 2.3050 - val_accuracy: 0.0982\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 14s 143ms/step - loss: 2.3068 - accuracy: 0.0954 - val_loss: 2.3051 - val_accuracy: 0.1026\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 14s 142ms/step - loss: 2.3056 - accuracy: 0.0953 - val_loss: 2.3068 - val_accuracy: 0.0990\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 14s 145ms/step - loss: 2.3055 - accuracy: 0.1008 - val_loss: 2.3041 - val_accuracy: 0.0994\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 14s 145ms/step - loss: 2.3052 - accuracy: 0.1029 - val_loss: 2.3059 - val_accuracy: 0.0982\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 14s 140ms/step - loss: 2.3066 - accuracy: 0.0978 - val_loss: 2.3045 - val_accuracy: 0.0976\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-0.0976  \u001b[0m | \u001b[0m103.3    \u001b[0m | \u001b[0m0.04073  \u001b[0m |\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 14s 89ms/step - loss: 2.3080 - accuracy: 0.1005 - val_loss: 2.3065 - val_accuracy: 0.1026\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 14s 89ms/step - loss: 2.3069 - accuracy: 0.0998 - val_loss: 2.3086 - val_accuracy: 0.1014\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 14s 92ms/step - loss: 2.3060 - accuracy: 0.1017 - val_loss: 2.3070 - val_accuracy: 0.1014\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 14s 88ms/step - loss: 2.3074 - accuracy: 0.1011 - val_loss: 2.3093 - val_accuracy: 0.1008\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 14s 86ms/step - loss: 2.3077 - accuracy: 0.1023 - val_loss: 2.3082 - val_accuracy: 0.1024\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 14s 90ms/step - loss: 2.3077 - accuracy: 0.1015 - val_loss: 2.3098 - val_accuracy: 0.0982\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 14s 90ms/step - loss: 2.3072 - accuracy: 0.1015 - val_loss: 2.3086 - val_accuracy: 0.1024\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 14s 90ms/step - loss: 2.3070 - accuracy: 0.0988 - val_loss: 2.3057 - val_accuracy: 0.1010\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 14s 88ms/step - loss: 2.3064 - accuracy: 0.0975 - val_loss: 2.3055 - val_accuracy: 0.1026\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 14s 89ms/step - loss: 2.3074 - accuracy: 0.1029 - val_loss: 2.3063 - val_accuracy: 0.0990\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-0.099   \u001b[0m | \u001b[0m64.07    \u001b[0m | \u001b[0m0.05348  \u001b[0m |\n",
      "Epoch 1/10\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 2.3051 - accuracy: 0.1012 - val_loss: 2.3040 - val_accuracy: 0.0994\n",
      "Epoch 2/10\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 2.3039 - accuracy: 0.0979 - val_loss: 2.3041 - val_accuracy: 0.1008\n",
      "Epoch 3/10\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 2.3037 - accuracy: 0.1032 - val_loss: 2.3039 - val_accuracy: 0.1024\n",
      "Epoch 4/10\n",
      "52/52 [==============================] - 13s 257ms/step - loss: 2.3035 - accuracy: 0.0972 - val_loss: 2.3035 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "52/52 [==============================] - 13s 258ms/step - loss: 2.3043 - accuracy: 0.0977 - val_loss: 2.3040 - val_accuracy: 0.1014\n",
      "Epoch 6/10\n",
      "52/52 [==============================] - 13s 260ms/step - loss: 2.3034 - accuracy: 0.1032 - val_loss: 2.3043 - val_accuracy: 0.0994\n",
      "Epoch 7/10\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 2.3038 - accuracy: 0.0971 - val_loss: 2.3044 - val_accuracy: 0.1024\n",
      "Epoch 8/10\n",
      "52/52 [==============================] - 13s 253ms/step - loss: 2.3041 - accuracy: 0.0962 - val_loss: 2.3038 - val_accuracy: 0.1024\n",
      "Epoch 9/10\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 2.3038 - accuracy: 0.0968 - val_loss: 2.3032 - val_accuracy: 0.1024\n",
      "Epoch 10/10\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 2.3038 - accuracy: 0.0981 - val_loss: 2.3040 - val_accuracy: 0.0990\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-0.099   \u001b[0m | \u001b[0m194.8    \u001b[0m | \u001b[0m0.02756  \u001b[0m |\n",
      "Epoch 1/10\n",
      "82/82 [==============================] - 14s 166ms/step - loss: 2.3073 - accuracy: 0.1001 - val_loss: 2.3159 - val_accuracy: 0.0990\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 14s 168ms/step - loss: 2.3064 - accuracy: 0.1013 - val_loss: 2.3057 - val_accuracy: 0.0982\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 14s 166ms/step - loss: 2.3060 - accuracy: 0.0964 - val_loss: 2.3069 - val_accuracy: 0.0994\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 13s 164ms/step - loss: 2.3068 - accuracy: 0.1014 - val_loss: 2.3073 - val_accuracy: 0.0990\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 13s 164ms/step - loss: 2.3064 - accuracy: 0.1004 - val_loss: 2.3065 - val_accuracy: 0.0994\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 13s 163ms/step - loss: 2.3080 - accuracy: 0.0984 - val_loss: 2.3056 - val_accuracy: 0.0976\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 13s 163ms/step - loss: 2.3061 - accuracy: 0.0923 - val_loss: 2.3075 - val_accuracy: 0.0982\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 14s 165ms/step - loss: 2.3062 - accuracy: 0.0980 - val_loss: 2.3054 - val_accuracy: 0.1010\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 13s 164ms/step - loss: 2.3060 - accuracy: 0.1009 - val_loss: 2.3064 - val_accuracy: 0.0982\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 13s 164ms/step - loss: 2.3064 - accuracy: 0.0941 - val_loss: 2.3080 - val_accuracy: 0.0982\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-0.0982  \u001b[0m | \u001b[0m123.7    \u001b[0m | \u001b[0m0.06738  \u001b[0m |\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 13s 605ms/step - loss: 2.3041 - accuracy: 0.1010 - val_loss: 2.3042 - val_accuracy: 0.0976\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 13s 607ms/step - loss: 2.3041 - accuracy: 0.0998 - val_loss: 2.3036 - val_accuracy: 0.0990\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 13s 608ms/step - loss: 2.3034 - accuracy: 0.1001 - val_loss: 2.3033 - val_accuracy: 0.0976\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 13s 608ms/step - loss: 2.3037 - accuracy: 0.1003 - val_loss: 2.3031 - val_accuracy: 0.1008\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 13s 600ms/step - loss: 2.3043 - accuracy: 0.0943 - val_loss: 2.3037 - val_accuracy: 0.0990\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 13s 613ms/step - loss: 2.3032 - accuracy: 0.0969 - val_loss: 2.3033 - val_accuracy: 0.0976\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 14s 644ms/step - loss: 2.3040 - accuracy: 0.0963 - val_loss: 2.3036 - val_accuracy: 0.0982\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 14s 623ms/step - loss: 2.3033 - accuracy: 0.0991 - val_loss: 2.3028 - val_accuracy: 0.1024\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 14s 631ms/step - loss: 2.3037 - accuracy: 0.0954 - val_loss: 2.3038 - val_accuracy: 0.1024\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 14s 627ms/step - loss: 2.3040 - accuracy: 0.0928 - val_loss: 2.3038 - val_accuracy: 0.1008\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-0.1008  \u001b[0m | \u001b[0m468.7    \u001b[0m | \u001b[0m0.04167  \u001b[0m |\n",
      "Epoch 1/10\n",
      "90/90 [==============================] - 14s 154ms/step - loss: 2.3080 - accuracy: 0.0966 - val_loss: 2.3049 - val_accuracy: 0.1008\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 14s 151ms/step - loss: 2.3069 - accuracy: 0.1000 - val_loss: 2.3061 - val_accuracy: 0.1024\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 14s 157ms/step - loss: 2.3071 - accuracy: 0.0970 - val_loss: 2.3047 - val_accuracy: 0.0990\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 2.3089 - accuracy: 0.0988 - val_loss: 2.3068 - val_accuracy: 0.0994\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 16s 175ms/step - loss: 2.3069 - accuracy: 0.0980 - val_loss: 2.3066 - val_accuracy: 0.1014\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 14s 158ms/step - loss: 2.3069 - accuracy: 0.0996 - val_loss: 2.3049 - val_accuracy: 0.0982\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 14s 154ms/step - loss: 2.3075 - accuracy: 0.1013 - val_loss: 2.3059 - val_accuracy: 0.0994\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 14s 154ms/step - loss: 2.3072 - accuracy: 0.0980 - val_loss: 2.3077 - val_accuracy: 0.0990\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 14s 161ms/step - loss: 2.3079 - accuracy: 0.1026 - val_loss: 2.3159 - val_accuracy: 0.0990\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 14s 153ms/step - loss: 2.3090 - accuracy: 0.0982 - val_loss: 2.3050 - val_accuracy: 0.1024\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-0.1024  \u001b[0m | \u001b[0m112.7    \u001b[0m | \u001b[0m0.06844  \u001b[0m |\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 13s 496ms/step - loss: 2.3046 - accuracy: 0.0982 - val_loss: 2.3047 - val_accuracy: 0.1024\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 13s 489ms/step - loss: 2.3041 - accuracy: 0.1008 - val_loss: 2.3032 - val_accuracy: 0.0990\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 13s 488ms/step - loss: 2.3038 - accuracy: 0.1031 - val_loss: 2.3038 - val_accuracy: 0.1008\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 13s 487ms/step - loss: 2.3039 - accuracy: 0.0994 - val_loss: 2.3033 - val_accuracy: 0.1008\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 14s 507ms/step - loss: 2.3039 - accuracy: 0.1016 - val_loss: 2.3040 - val_accuracy: 0.0982\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 13s 499ms/step - loss: 2.3046 - accuracy: 0.0982 - val_loss: 2.3037 - val_accuracy: 0.1024\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 14s 522ms/step - loss: 2.3035 - accuracy: 0.0993 - val_loss: 2.3031 - val_accuracy: 0.1008\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 13s 498ms/step - loss: 2.3038 - accuracy: 0.0975 - val_loss: 2.3029 - val_accuracy: 0.1008\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 13s 493ms/step - loss: 2.3041 - accuracy: 0.0972 - val_loss: 2.3038 - val_accuracy: 0.0994\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 13s 494ms/step - loss: 2.3035 - accuracy: 0.0961 - val_loss: 2.3033 - val_accuracy: 0.1026\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-0.1026  \u001b[0m | \u001b[0m376.2    \u001b[0m | \u001b[0m0.04005  \u001b[0m |\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 14s 98ms/step - loss: 2.3086 - accuracy: 0.1026 - val_loss: 2.3175 - val_accuracy: 0.0982\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 14s 98ms/step - loss: 2.3096 - accuracy: 0.1015 - val_loss: 2.3069 - val_accuracy: 0.1008\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 14s 96ms/step - loss: 2.3068 - accuracy: 0.0981 - val_loss: 2.3130 - val_accuracy: 0.0982\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 14s 96ms/step - loss: 2.3080 - accuracy: 0.0990 - val_loss: 2.3074 - val_accuracy: 0.0976\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 14s 96ms/step - loss: 2.3076 - accuracy: 0.0978 - val_loss: 2.3058 - val_accuracy: 0.0976\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 14s 96ms/step - loss: 2.3081 - accuracy: 0.1008 - val_loss: 2.3092 - val_accuracy: 0.1008\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 14s 97ms/step - loss: 2.3093 - accuracy: 0.0963 - val_loss: 2.3046 - val_accuracy: 0.1024\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 14s 98ms/step - loss: 2.3057 - accuracy: 0.1040 - val_loss: 2.3054 - val_accuracy: 0.0976\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 14s 96ms/step - loss: 2.3082 - accuracy: 0.0962 - val_loss: 2.3058 - val_accuracy: 0.0982\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 14s 97ms/step - loss: 2.3087 - accuracy: 0.0971 - val_loss: 2.3053 - val_accuracy: 0.1008\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-0.1008  \u001b[0m | \u001b[0m70.27    \u001b[0m | \u001b[0m0.06275  \u001b[0m |\n",
      "Epoch 1/10\n",
      "271/271 [==============================] - 15s 53ms/step - loss: 2.3079 - accuracy: 0.1000 - val_loss: 2.3108 - val_accuracy: 0.1014\n",
      "Epoch 2/10\n",
      "271/271 [==============================] - 14s 53ms/step - loss: 2.3071 - accuracy: 0.1014 - val_loss: 2.3086 - val_accuracy: 0.1008\n",
      "Epoch 3/10\n",
      "271/271 [==============================] - 14s 53ms/step - loss: 2.3078 - accuracy: 0.0957 - val_loss: 2.3062 - val_accuracy: 0.1008\n",
      "Epoch 4/10\n",
      "271/271 [==============================] - 14s 53ms/step - loss: 2.3081 - accuracy: 0.0983 - val_loss: 2.3049 - val_accuracy: 0.0976\n",
      "Epoch 5/10\n",
      "271/271 [==============================] - 14s 52ms/step - loss: 2.3074 - accuracy: 0.1012 - val_loss: 2.3069 - val_accuracy: 0.0982\n",
      "Epoch 6/10\n",
      "271/271 [==============================] - 14s 52ms/step - loss: 2.3079 - accuracy: 0.0987 - val_loss: 2.3050 - val_accuracy: 0.1024\n",
      "Epoch 7/10\n",
      "271/271 [==============================] - 14s 52ms/step - loss: 2.3071 - accuracy: 0.0993 - val_loss: 2.3043 - val_accuracy: 0.1026\n",
      "Epoch 8/10\n",
      "271/271 [==============================] - 14s 52ms/step - loss: 2.3068 - accuracy: 0.0997 - val_loss: 2.3089 - val_accuracy: 0.1008\n",
      "Epoch 9/10\n",
      "271/271 [==============================] - 14s 52ms/step - loss: 2.3082 - accuracy: 0.0963 - val_loss: 2.3082 - val_accuracy: 0.1008\n",
      "Epoch 10/10\n",
      "271/271 [==============================] - 14s 53ms/step - loss: 2.3074 - accuracy: 0.1010 - val_loss: 2.3070 - val_accuracy: 0.1024\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-0.1024  \u001b[0m | \u001b[0m37.28    \u001b[0m | \u001b[0m0.03755  \u001b[0m |\n",
      "Epoch 1/10\n",
      "73/73 [==============================] - 13s 183ms/step - loss: 2.3067 - accuracy: 0.1038 - val_loss: 2.3128 - val_accuracy: 0.0994\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 13s 182ms/step - loss: 2.3089 - accuracy: 0.0976 - val_loss: 2.3042 - val_accuracy: 0.1014\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 13s 182ms/step - loss: 2.3073 - accuracy: 0.0994 - val_loss: 2.3059 - val_accuracy: 0.0994\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 13s 183ms/step - loss: 2.3069 - accuracy: 0.0964 - val_loss: 2.3049 - val_accuracy: 0.1008\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 13s 183ms/step - loss: 2.3063 - accuracy: 0.0995 - val_loss: 2.3068 - val_accuracy: 0.0982\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 13s 185ms/step - loss: 2.3069 - accuracy: 0.0988 - val_loss: 2.3060 - val_accuracy: 0.1008\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 13s 183ms/step - loss: 2.3061 - accuracy: 0.1004 - val_loss: 2.3064 - val_accuracy: 0.0990\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 14s 187ms/step - loss: 2.3085 - accuracy: 0.1010 - val_loss: 2.3087 - val_accuracy: 0.1024\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 14s 192ms/step - loss: 2.3078 - accuracy: 0.1007 - val_loss: 2.3071 - val_accuracy: 0.0990\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 14s 194ms/step - loss: 2.3064 - accuracy: 0.0939 - val_loss: 2.3080 - val_accuracy: 0.0982\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-0.0982  \u001b[0m | \u001b[0m137.4    \u001b[0m | \u001b[0m0.0833   \u001b[0m |\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 14s 370ms/step - loss: 2.3080 - accuracy: 0.0961 - val_loss: 2.3035 - val_accuracy: 0.1024\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 14s 376ms/step - loss: 2.3048 - accuracy: 0.1031 - val_loss: 2.3071 - val_accuracy: 0.1024\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 14s 376ms/step - loss: 2.3059 - accuracy: 0.0959 - val_loss: 2.3056 - val_accuracy: 0.1026\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 14s 371ms/step - loss: 2.3054 - accuracy: 0.0986 - val_loss: 2.3045 - val_accuracy: 0.0994\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 14s 373ms/step - loss: 2.3061 - accuracy: 0.0987 - val_loss: 2.3114 - val_accuracy: 0.0994\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 14s 381ms/step - loss: 2.3068 - accuracy: 0.0981 - val_loss: 2.3065 - val_accuracy: 0.0994\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 14s 395ms/step - loss: 2.3068 - accuracy: 0.1030 - val_loss: 2.3068 - val_accuracy: 0.1026\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 14s 382ms/step - loss: 2.3053 - accuracy: 0.1008 - val_loss: 2.3058 - val_accuracy: 0.0982\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 14s 380ms/step - loss: 2.3053 - accuracy: 0.1062 - val_loss: 2.3090 - val_accuracy: 0.0994\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 14s 369ms/step - loss: 2.3063 - accuracy: 0.0971 - val_loss: 2.3056 - val_accuracy: 0.1014\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-0.1014  \u001b[0m | \u001b[0m277.0    \u001b[0m | \u001b[0m0.07788  \u001b[0m |\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 14s 614ms/step - loss: 2.3054 - accuracy: 0.1021 - val_loss: 2.3060 - val_accuracy: 0.0982\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 14s 626ms/step - loss: 2.3046 - accuracy: 0.1015 - val_loss: 2.3035 - val_accuracy: 0.1024\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 14s 616ms/step - loss: 2.3052 - accuracy: 0.0966 - val_loss: 2.3044 - val_accuracy: 0.1024\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 14s 630ms/step - loss: 2.3047 - accuracy: 0.0972 - val_loss: 2.3043 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 14s 612ms/step - loss: 2.3047 - accuracy: 0.0977 - val_loss: 2.3040 - val_accuracy: 0.0976\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 14s 602ms/step - loss: 2.3049 - accuracy: 0.0998 - val_loss: 2.3034 - val_accuracy: 0.0994\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 15s 643ms/step - loss: 2.3035 - accuracy: 0.1013 - val_loss: 2.3048 - val_accuracy: 0.0982\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 14s 618ms/step - loss: 2.3049 - accuracy: 0.0980 - val_loss: 2.3055 - val_accuracy: 0.1024\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 13s 589ms/step - loss: 2.3041 - accuracy: 0.0978 - val_loss: 2.3031 - val_accuracy: 0.1008\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 14s 615ms/step - loss: 2.3048 - accuracy: 0.0979 - val_loss: 2.3042 - val_accuracy: 0.1008\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-0.1008  \u001b[0m | \u001b[0m437.2    \u001b[0m | \u001b[0m0.06101  \u001b[0m |\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 14s 567ms/step - loss: 2.3065 - accuracy: 0.1018 - val_loss: 2.3037 - val_accuracy: 0.1008\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 14s 550ms/step - loss: 2.3061 - accuracy: 0.0996 - val_loss: 2.3052 - val_accuracy: 0.1008\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 14s 555ms/step - loss: 2.3041 - accuracy: 0.0981 - val_loss: 2.3048 - val_accuracy: 0.0976\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 14s 556ms/step - loss: 2.3037 - accuracy: 0.1011 - val_loss: 2.3046 - val_accuracy: 0.1026\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 14s 568ms/step - loss: 2.3066 - accuracy: 0.0980 - val_loss: 2.3041 - val_accuracy: 0.1026\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 14s 581ms/step - loss: 2.3050 - accuracy: 0.1036 - val_loss: 2.3071 - val_accuracy: 0.1008\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 14s 582ms/step - loss: 2.3051 - accuracy: 0.1005 - val_loss: 2.3055 - val_accuracy: 0.0982\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 14s 559ms/step - loss: 2.3049 - accuracy: 0.0953 - val_loss: 2.3050 - val_accuracy: 0.0982\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 14s 562ms/step - loss: 2.3057 - accuracy: 0.0983 - val_loss: 2.3046 - val_accuracy: 0.1008\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 14s 558ms/step - loss: 2.3046 - accuracy: 0.0941 - val_loss: 2.3046 - val_accuracy: 0.0982\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-0.0982  \u001b[0m | \u001b[0m411.9    \u001b[0m | \u001b[0m0.07688  \u001b[0m |\n",
      "Epoch 1/10\n",
      "278/278 [==============================] - 16s 58ms/step - loss: 2.3077 - accuracy: 0.0985 - val_loss: 2.3059 - val_accuracy: 0.1024\n",
      "Epoch 2/10\n",
      "278/278 [==============================] - 16s 56ms/step - loss: 2.3078 - accuracy: 0.0935 - val_loss: 2.3069 - val_accuracy: 0.0982\n",
      "Epoch 3/10\n",
      "278/278 [==============================] - 15s 55ms/step - loss: 2.3074 - accuracy: 0.0983 - val_loss: 2.3043 - val_accuracy: 0.1026\n",
      "Epoch 4/10\n",
      "278/278 [==============================] - 15s 53ms/step - loss: 2.3068 - accuracy: 0.1018 - val_loss: 2.3048 - val_accuracy: 0.1024\n",
      "Epoch 5/10\n",
      "278/278 [==============================] - 15s 53ms/step - loss: 2.3064 - accuracy: 0.1021 - val_loss: 2.3071 - val_accuracy: 0.1008\n",
      "Epoch 6/10\n",
      "278/278 [==============================] - 15s 54ms/step - loss: 2.3066 - accuracy: 0.0975 - val_loss: 2.3070 - val_accuracy: 0.1008\n",
      "Epoch 7/10\n",
      "278/278 [==============================] - 15s 54ms/step - loss: 2.3079 - accuracy: 0.0964 - val_loss: 2.3057 - val_accuracy: 0.1010\n",
      "Epoch 8/10\n",
      "278/278 [==============================] - 15s 54ms/step - loss: 2.3076 - accuracy: 0.1009 - val_loss: 2.3059 - val_accuracy: 0.1008\n",
      "Epoch 9/10\n",
      "278/278 [==============================] - 15s 53ms/step - loss: 2.3066 - accuracy: 0.1017 - val_loss: 2.3047 - val_accuracy: 0.1024\n",
      "Epoch 10/10\n",
      "278/278 [==============================] - 15s 53ms/step - loss: 2.3071 - accuracy: 0.0988 - val_loss: 2.3052 - val_accuracy: 0.0994\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-0.0994  \u001b[0m | \u001b[0m36.96    \u001b[0m | \u001b[0m0.03656  \u001b[0m |\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 14s 339ms/step - loss: 2.3055 - accuracy: 0.0972 - val_loss: 2.3038 - val_accuracy: 0.1010\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 13s 339ms/step - loss: 2.3041 - accuracy: 0.1013 - val_loss: 2.3055 - val_accuracy: 0.1014\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 14s 350ms/step - loss: 2.3057 - accuracy: 0.1016 - val_loss: 2.3057 - val_accuracy: 0.0990\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 14s 347ms/step - loss: 2.3051 - accuracy: 0.0993 - val_loss: 2.3062 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 14s 360ms/step - loss: 2.3054 - accuracy: 0.0991 - val_loss: 2.3058 - val_accuracy: 0.1008\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 15s 368ms/step - loss: 2.3042 - accuracy: 0.0997 - val_loss: 2.3048 - val_accuracy: 0.0982\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 15s 375ms/step - loss: 2.3042 - accuracy: 0.1010 - val_loss: 2.3063 - val_accuracy: 0.0990\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 14s 350ms/step - loss: 2.3045 - accuracy: 0.0963 - val_loss: 2.3029 - val_accuracy: 0.1024\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 14s 356ms/step - loss: 2.3045 - accuracy: 0.1013 - val_loss: 2.3041 - val_accuracy: 0.1024\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 14s 354ms/step - loss: 2.3053 - accuracy: 0.1005 - val_loss: 2.3064 - val_accuracy: 0.0990\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-0.099   \u001b[0m | \u001b[0m253.5    \u001b[0m | \u001b[0m0.04885  \u001b[0m |\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 14s 361ms/step - loss: 2.3036 - accuracy: 0.0989 - val_loss: 2.3028 - val_accuracy: 0.1024\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 14s 362ms/step - loss: 2.3028 - accuracy: 0.1038 - val_loss: 2.3028 - val_accuracy: 0.0982\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 13s 354ms/step - loss: 2.3027 - accuracy: 0.1018 - val_loss: 2.3030 - val_accuracy: 0.1024\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 13s 355ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3032 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 13s 355ms/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3029 - val_accuracy: 0.1024\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 14s 371ms/step - loss: 2.3025 - accuracy: 0.1014 - val_loss: 2.3030 - val_accuracy: 0.0994\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 14s 365ms/step - loss: 2.3028 - accuracy: 0.1018 - val_loss: 2.3029 - val_accuracy: 0.1024\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 14s 372ms/step - loss: 2.3028 - accuracy: 0.1037 - val_loss: 2.3031 - val_accuracy: 0.0994\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 14s 368ms/step - loss: 2.3027 - accuracy: 0.1016 - val_loss: 2.3031 - val_accuracy: 0.0982\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 14s 362ms/step - loss: 2.3026 - accuracy: 0.0994 - val_loss: 2.3028 - val_accuracy: 0.1024\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-0.1024  \u001b[0m | \u001b[0m269.3    \u001b[0m | \u001b[0m0.009217 \u001b[0m |\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 14s 253ms/step - loss: 2.3037 - accuracy: 0.0983 - val_loss: 2.3033 - val_accuracy: 0.0976\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 14s 255ms/step - loss: 2.3033 - accuracy: 0.1028 - val_loss: 2.3036 - val_accuracy: 0.1008\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 14s 251ms/step - loss: 2.3032 - accuracy: 0.1026 - val_loss: 2.3042 - val_accuracy: 0.0982\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 14s 256ms/step - loss: 2.3041 - accuracy: 0.1008 - val_loss: 2.3039 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 14s 260ms/step - loss: 2.3035 - accuracy: 0.1002 - val_loss: 2.3039 - val_accuracy: 0.1024\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 14s 262ms/step - loss: 2.3038 - accuracy: 0.0998 - val_loss: 2.3029 - val_accuracy: 0.1024\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 14s 259ms/step - loss: 2.3037 - accuracy: 0.0963 - val_loss: 2.3035 - val_accuracy: 0.1024\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 14s 259ms/step - loss: 2.3037 - accuracy: 0.1002 - val_loss: 2.3036 - val_accuracy: 0.0982\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 14s 258ms/step - loss: 2.3036 - accuracy: 0.1021 - val_loss: 2.3029 - val_accuracy: 0.1024\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 14s 257ms/step - loss: 2.3035 - accuracy: 0.1008 - val_loss: 2.3032 - val_accuracy: 0.1008\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-0.1008  \u001b[0m | \u001b[0m182.9    \u001b[0m | \u001b[0m0.02152  \u001b[0m |\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 14s 616ms/step - loss: 2.3034 - accuracy: 0.1011 - val_loss: 2.3030 - val_accuracy: 0.1024\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 14s 628ms/step - loss: 2.3030 - accuracy: 0.1020 - val_loss: 2.3040 - val_accuracy: 0.0982\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 14s 630ms/step - loss: 2.3028 - accuracy: 0.1010 - val_loss: 2.3032 - val_accuracy: 0.1024\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 14s 601ms/step - loss: 2.3027 - accuracy: 0.1032 - val_loss: 2.3029 - val_accuracy: 0.1024\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 13s 591ms/step - loss: 2.3026 - accuracy: 0.1022 - val_loss: 2.3032 - val_accuracy: 0.1008\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 14s 596ms/step - loss: 2.3033 - accuracy: 0.0995 - val_loss: 2.3035 - val_accuracy: 0.1014\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 14s 599ms/step - loss: 2.3031 - accuracy: 0.1015 - val_loss: 2.3036 - val_accuracy: 0.1008\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 13s 593ms/step - loss: 2.3028 - accuracy: 0.1027 - val_loss: 2.3034 - val_accuracy: 0.0994\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 14s 632ms/step - loss: 2.3031 - accuracy: 0.0948 - val_loss: 2.3030 - val_accuracy: 0.0990\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 14s 606ms/step - loss: 2.3032 - accuracy: 0.1004 - val_loss: 2.3028 - val_accuracy: 0.1024\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-0.1024  \u001b[0m | \u001b[0m454.6    \u001b[0m | \u001b[0m0.0133   \u001b[0m |\n",
      "Epoch 1/10\n",
      "233/233 [==============================] - 15s 62ms/step - loss: 2.3029 - accuracy: 0.1015 - val_loss: 2.3028 - val_accuracy: 0.1024\n",
      "Epoch 2/10\n",
      "233/233 [==============================] - 14s 61ms/step - loss: 2.3028 - accuracy: 0.1028 - val_loss: 2.3031 - val_accuracy: 0.0982\n",
      "Epoch 3/10\n",
      "233/233 [==============================] - 15s 66ms/step - loss: 2.3026 - accuracy: 0.0993 - val_loss: 2.3029 - val_accuracy: 0.1024\n",
      "Epoch 4/10\n",
      "233/233 [==============================] - 15s 64ms/step - loss: 2.3028 - accuracy: 0.0975 - val_loss: 2.3029 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "233/233 [==============================] - 15s 63ms/step - loss: 2.3027 - accuracy: 0.1018 - val_loss: 2.3029 - val_accuracy: 0.1024\n",
      "Epoch 6/10\n",
      "233/233 [==============================] - 15s 62ms/step - loss: 2.3028 - accuracy: 0.0997 - val_loss: 2.3029 - val_accuracy: 0.1024\n",
      "Epoch 7/10\n",
      "233/233 [==============================] - 16s 68ms/step - loss: 2.3027 - accuracy: 0.1011 - val_loss: 2.3030 - val_accuracy: 0.1024\n",
      "Epoch 8/10\n",
      "233/233 [==============================] - 16s 68ms/step - loss: 2.3028 - accuracy: 0.1027 - val_loss: 2.3030 - val_accuracy: 0.0982\n",
      "Epoch 9/10\n",
      "233/233 [==============================] - 16s 68ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3030 - val_accuracy: 0.0982\n",
      "Epoch 10/10\n",
      "233/233 [==============================] - 16s 69ms/step - loss: 2.3027 - accuracy: 0.1004 - val_loss: 2.3030 - val_accuracy: 0.1008\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-0.1008  \u001b[0m | \u001b[0m43.13    \u001b[0m | \u001b[0m0.002859 \u001b[0m |\n",
      "Epoch 1/10\n",
      "164/164 [==============================] - 15s 91ms/step - loss: 2.3071 - accuracy: 0.0965 - val_loss: 2.3080 - val_accuracy: 0.0982\n",
      "Epoch 2/10\n",
      "164/164 [==============================] - 14s 86ms/step - loss: 2.3058 - accuracy: 0.1037 - val_loss: 2.3078 - val_accuracy: 0.1008\n",
      "Epoch 3/10\n",
      "164/164 [==============================] - 14s 86ms/step - loss: 2.3074 - accuracy: 0.0962 - val_loss: 2.3051 - val_accuracy: 0.0982\n",
      "Epoch 4/10\n",
      "164/164 [==============================] - 14s 88ms/step - loss: 2.3059 - accuracy: 0.0986 - val_loss: 2.3070 - val_accuracy: 0.0976\n",
      "Epoch 5/10\n",
      "164/164 [==============================] - 16s 97ms/step - loss: 2.3061 - accuracy: 0.1017 - val_loss: 2.3080 - val_accuracy: 0.0976\n",
      "Epoch 6/10\n",
      "164/164 [==============================] - 16s 97ms/step - loss: 2.3062 - accuracy: 0.0982 - val_loss: 2.3039 - val_accuracy: 0.0990\n",
      "Epoch 7/10\n",
      "164/164 [==============================] - 15s 90ms/step - loss: 2.3065 - accuracy: 0.0947 - val_loss: 2.3099 - val_accuracy: 0.0976\n",
      "Epoch 8/10\n",
      "164/164 [==============================] - 15s 89ms/step - loss: 2.3075 - accuracy: 0.0970 - val_loss: 2.3046 - val_accuracy: 0.0982\n",
      "Epoch 9/10\n",
      "164/164 [==============================] - 14s 88ms/step - loss: 2.3059 - accuracy: 0.0984 - val_loss: 2.3053 - val_accuracy: 0.0994\n",
      "Epoch 10/10\n",
      "164/164 [==============================] - 14s 88ms/step - loss: 2.3059 - accuracy: 0.1020 - val_loss: 2.3041 - val_accuracy: 0.1008\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-0.1008  \u001b[0m | \u001b[0m61.9     \u001b[0m | \u001b[0m0.03903  \u001b[0m |\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 13s 514ms/step - loss: 2.3049 - accuracy: 0.0976 - val_loss: 2.3030 - val_accuracy: 0.0994\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 13s 514ms/step - loss: 2.3035 - accuracy: 0.0999 - val_loss: 2.3036 - val_accuracy: 0.0982\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 13s 516ms/step - loss: 2.3035 - accuracy: 0.0978 - val_loss: 2.3028 - val_accuracy: 0.1014\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 14s 531ms/step - loss: 2.3036 - accuracy: 0.0982 - val_loss: 2.3032 - val_accuracy: 0.1024\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 13s 511ms/step - loss: 2.3033 - accuracy: 0.0980 - val_loss: 2.3032 - val_accuracy: 0.1008\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 14s 540ms/step - loss: 2.3034 - accuracy: 0.1002 - val_loss: 2.3030 - val_accuracy: 0.0982\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 14s 544ms/step - loss: 2.3031 - accuracy: 0.0987 - val_loss: 2.3032 - val_accuracy: 0.0994\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 14s 557ms/step - loss: 2.3036 - accuracy: 0.0987 - val_loss: 2.3032 - val_accuracy: 0.1024\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 14s 548ms/step - loss: 2.3033 - accuracy: 0.0954 - val_loss: 2.3030 - val_accuracy: 0.1008\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 15s 575ms/step - loss: 2.3034 - accuracy: 0.0970 - val_loss: 2.3032 - val_accuracy: 0.1026\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-0.1026  \u001b[0m | \u001b[0m386.6    \u001b[0m | \u001b[0m0.02988  \u001b[0m |\n",
      "=================================================\n",
      "{'target': -0.09759999811649323, 'params': {'batch_size': 32.054899912325546, 'learning_rate': 0.030303024005920793}}\n",
      "CPU times: user 10h 48min 55s, sys: 11min, total: 10h 59min 56s\n",
      "Wall time: 1h 34min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def BayesOptimization(learning_rate, batch_size):\n",
    "    # Convert hyperparameters to appropriate format\n",
    "    batch_size = int(batch_size)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate), metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Early stopping\n",
    "    # disabled because it prevents convergence\n",
    "    #early_stopping = EarlyStopping(monitor='val_loss', patience=4) \n",
    "\n",
    "    # Train your model and return the validation error\n",
    "    history = model.fit(X_labeled, y_labeled, batch_size=batch_size, validation_data=(X_val, y_val), epochs=10)\n",
    "    # Using the negative validation accuracy as a score to maximize accuracy\n",
    "    score = -history.history['val_accuracy'][-1]\n",
    "\n",
    "    return score\n",
    "\n",
    "def optimize_cnn():\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=BayesOptimization,\n",
    "        pbounds={'learning_rate': (0.0001, 0.1), 'batch_size': (32, 512)},\n",
    "        verbose=2,\n",
    "        random_state=1,\n",
    "    )\n",
    "    # n_iter value to change the number of attemps\n",
    "    optimizer.maximize(init_points=10, n_iter=30)\n",
    "\n",
    "    # Print Optimizer results\n",
    "    print(optimizer.max)\n",
    "    \n",
    "    # Return optimizer for metrics\n",
    "    return optimizer\n",
    "\n",
    "optimizer = optimize_cnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932667f",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3f6e0",
   "metadata": {
    "id": "t8iA1QEK_UNl"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('/Users/air/Desktop/FinalProject/Models/TargetBayesOpti.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the Target Model Architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7278898",
   "metadata": {
    "id": "IFAQrnFo5IZS"
   },
   "source": [
    "# Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7837f514",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "QPlDyyX65PKh",
    "noteable": {},
    "outputId": "1e4172d7-2d3f-42f4-b719-111604eee6a2"
   },
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "eval_result = model.evaluate(X_val, y_val)\n",
    "print(\"\\nTest loss, Test accuracy:\", eval_result)\n",
    "\n",
    "# Plots\n",
    "fig, axs = plt.subplots(2)\n",
    "\n",
    "# summarize history for accuracy\n",
    "axs[0].plot(optimizer.max['params']['history'].history['accuracy'])\n",
    "axs[0].plot(optimizer.max['params']['history'].history['val_accuracy'])\n",
    "axs[0].set_title('Model accuracy')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "axs[1].plot(optimizer.max['params']['history'].history['loss'])\n",
    "axs[1].plot(optimizer.max['params']['history'].history['val_loss'])\n",
    "axs[1].set_title('Model loss')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# Plotting the Metrics\n",
    "plt.tight_layout()\n",
    "plt.show()me 'optimizer' is not defined\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "noteable": {
   "last_delta_id": "a055dfd5-4922-40e0-9ff3-9e859da74c3d",
   "last_transaction_id": "d2cfa302-0719-49ca-8523-a5c6ca62a94e"
  },
  "nteract": {
   "version": "noteable@2.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
