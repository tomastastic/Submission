{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDgGN_5qzrIP"
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lf1vvX53BXBT",
    "outputId": "b02ff78e-0a0b-498e-e283-6886fe1295b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in /Applications/miniconda3/lib/python3.11/site-packages (1.3.5)\n",
      "Requirement already satisfied: packaging in /Applications/miniconda3/lib/python3.11/site-packages (from keras-tuner) (23.0)\n",
      "Requirement already satisfied: requests in /Applications/miniconda3/lib/python3.11/site-packages (from keras-tuner) (2.29.0)\n",
      "Requirement already satisfied: kt-legacy in /Applications/miniconda3/lib/python3.11/site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Applications/miniconda3/lib/python3.11/site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/miniconda3/lib/python3.11/site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Applications/miniconda3/lib/python3.11/site-packages (from requests->keras-tuner) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/miniconda3/lib/python3.11/site-packages (from requests->keras-tuner) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUZ9Zz-djo45",
    "outputId": "3a4bb99e-694d-44d9-da9e-bc13bf3a7f6c"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#NEW\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras_tuner.tuners import BayesianOptimization\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43XkYne0GXIf"
   },
   "source": [
    "# Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBelCxDXGc62",
    "outputId": "a994b91d-d673-4ac7-eb2b-b086fb0e58e6"
   },
   "outputs": [],
   "source": [
    "# path to local data directory\n",
    "data_dir = '/Users/air/Desktop/FinalProject/Data'\n",
    "\n",
    "# Load data\n",
    "X_rot_train = np.load(f'{data_dir}/X_rot_train.npy')\n",
    "y_rot_train = np.load(f'{data_dir}/y_rot_train.npy')\n",
    "\n",
    "X_rot_val = np.load(f'{data_dir}/X_rot_val.npy')\n",
    "y_rot_val = np.load(f'{data_dir}/y_rot_val.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4RSElybTbwi"
   },
   "source": [
    "# Creating a CNN and training it on rotations of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJGejh9hTY-g"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_model(hp):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
    "                            input_shape=[32, 32, 3]),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(4, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4])\n",
    "    hp_epochs = hp.Int('epochs', min_value = 5, max_value = 30, step = 5)\n",
    "\n",
    "    model.compile(optimizer = keras.optimizers.SGD(learning_rate=hp_learning_rate),\n",
    "                  loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQZbpuzEIYYe"
   },
   "source": [
    "# Run Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nSjB2udeAf6K",
    "outputId": "11ff20fe-bd7b-4fd5-c9a1-789533b42d95"
   },
   "outputs": [],
   "source": [
    "# Run Bayesian Optimization\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=1,\n",
    "    directory='/content/drive/MyDrive/A Goldsmiths /A Final Project/DEV/AutoBayesOptRot50epoch',\n",
    "    project_name='RotationPred',\n",
    "    overwrite=True #True in the tuner will overwrite, to continue from a previous state, set False\n",
    ")\n",
    "tuner.search_space_summary()\n",
    "tuner.search(X_rot_train, y_rot_train, epochs=50, validation_data=(X_rot_val, y_rot_val))\n",
    "\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "opt_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KdibQEzAv7b"
   },
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(opt_hps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YdVJMV6fAyDV"
   },
   "outputs": [],
   "source": [
    "# Checking the Model Architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzLi5AzLFwoQ"
   },
   "outputs": [],
   "source": [
    "#SAVE MODEL\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "model_name = \"Rot-PretextBayesian50epoch\"\n",
    "path = f\"/content/gdrive/MyDrive/A Goldsmiths /A Final Project/DEV/{model_name}\"\n",
    "model.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdWnPzH0A-AW"
   },
   "source": [
    "#New Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5YrHJGpBALL"
   },
   "outputs": [],
   "source": [
    "# Compute metrics and create plots\n",
    "predicted_labels = np.argmax(model.predict(X_rot_val), axis=1)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_rot_val, predicted_labels)\n",
    "print('Accuracy: ', accuracy)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_rot_val, predicted_labels)\n",
    "print('Confusion Matrix: ')\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KVt99eLtBDNN"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aF3I7xeRBJ0z"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Precision, Recall, F1-score with 'macro' average\n",
    "precision_macro = precision_score(y_rot_val, predicted_labels, average='macro')\n",
    "recall_macro = recall_score(y_rot_val, predicted_labels, average='macro')\n",
    "f1_macro = f1_score(y_rot_val, predicted_labels, average='macro')\n",
    "\n",
    "# Precision, Recall, F1-score with 'micro' average\n",
    "precision_micro = precision_score(y_rot_val, predicted_labels, average='micro')\n",
    "recall_micro = recall_score(y_rot_val, predicted_labels, average='micro')\n",
    "f1_micro = f1_score(y_rot_val, predicted_labels, average='micro')\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results = pd.DataFrame({\n",
    "    'Metric': ['Macro Precision', 'Macro Recall', 'Macro F1-score', 'Micro Precision', 'Micro Recall', 'Micro F1-score'],\n",
    "    'Score': [precision_macro, recall_macro, f1_macro, precision_micro, recall_micro, f1_micro]\n",
    "})\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsqhMA5-YgOV"
   },
   "source": [
    "##Unsupervised Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AuOVT-VYefj"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Predict the rotation of the validation set\n",
    "y_rot_val_pred = model.predict(X_rot_val).argmax(axis=1)  # Returns the indices of the maximum values along an axis\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_rot_val, y_rot_val_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_rot_val, y_rot_val_pred)\n",
    "print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "\n",
    "# Precision, Recall, F1-score with 'macro' average\n",
    "precision_macro = precision_score(y_rot_val, y_rot_val_pred, average='macro')\n",
    "recall_macro = recall_score(y_rot_val, y_rot_val_pred, average='macro')\n",
    "f1_macro = f1_score(y_rot_val, y_rot_val_pred, average='macro')\n",
    "print(f\"Macro Precision: {precision_macro}\")\n",
    "print(f\"Macro Recall: {recall_macro}\")\n",
    "print(f\"Macro F1-score: {f1_macro}\")\n",
    "\n",
    "# Precision, Recall, F1-score with 'micro' average\n",
    "precision_micro = precision_score(y_rot_val, y_rot_val_pred, average='micro')\n",
    "recall_micro = recall_score(y_rot_val, y_rot_val_pred, average='micro')\n",
    "f1_micro = f1_score(y_rot_val, y_rot_val_pred, average='micro')\n",
    "print(f\"Micro Precision: {precision_micro}\")\n",
    "print(f\"Micro Recall: {recall_micro}\")\n",
    "print(f\"Micro F1-score: {f1_micro}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_rot_val, y_rot_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dFYbAsNtmJ9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Predict the rotation of the validation set\n",
    "y_rot_val_pred = model.predict(X_rot_val).argmax(axis=1)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_rot_val, y_rot_val_pred)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_rot_val, y_rot_val_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Precision, Recall, F1-score with 'macro' average\n",
    "precision_macro = precision_score(y_rot_val, y_rot_val_pred, average='macro')\n",
    "recall_macro = recall_score(y_rot_val, y_rot_val_pred, average='macro')\n",
    "f1_macro = f1_score(y_rot_val, y_rot_val_pred, average='macro')\n",
    "\n",
    "# Precision, Recall, F1-score with 'micro' average\n",
    "precision_micro = precision_score(y_rot_val, y_rot_val_pred, average='micro')\n",
    "recall_micro = recall_score(y_rot_val, y_rot_val_pred, average='micro')\n",
    "f1_micro = f1_score(y_rot_val, y_rot_val_pred, average='micro')\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results = pd.DataFrame({\n",
    "    'Metric': ['Macro Precision', 'Macro Recall', 'Macro F1-score', 'Micro Precision', 'Micro Recall', 'Micro F1-score'],\n",
    "    'Score': [precision_macro, recall_macro, f1_macro, precision_micro, recall_micro, f1_micro]\n",
    "})\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncJgP7WSFfcY"
   },
   "outputs": [],
   "source": [
    "#SAVE MODEL\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "model_name = \"Unsupervised\"\n",
    "path = f\"/content/gdrive/MyDrive/A Goldsmiths /A Final Project/DEV/{model_name}\"\n",
    "model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nu9k0u2osVdL"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "model.save('Rot-PretextTask.h5')\n",
    "\n",
    "files.download('Rot-PretextTask.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2Qn8VxCYosW"
   },
   "source": [
    "#Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRtCynZBpI9P"
   },
   "outputs": [],
   "source": [
    "# Removing the top layer and addding a new top layer\n",
    "model.pop()\n",
    "model.add(keras.layers.Dense(10, name='dense_3', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30zca1Vcq1Mo"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Checking the changes in Model Architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iU9-UEJ8rS7X"
   },
   "outputs": [],
   "source": [
    "# Check the 'Trainable' status of each layer\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70p16Vb_ruj2"
   },
   "outputs": [],
   "source": [
    "# Freezing the Convolutional Layers while keeping Dense layers as Trainable\n",
    "for layer in model.layers:\n",
    "    if layer.name in ['dense_3', 'dense_1', 'dense', 'dropout', 'dropout_1']:\n",
    "      layer.trainable=True\n",
    "    else:\n",
    "      layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNAXyPxnsDQ0"
   },
   "outputs": [],
   "source": [
    "# Checking if the changes in 'Trainable' status of each layer have taken place\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCfNEe3-Zaex"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkfpr6CuZe2I"
   },
   "source": [
    "#DATA BITS START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UkrwLVmKshzl"
   },
   "outputs": [],
   "source": [
    "# Reshaping the Inputs\n",
    "X_labeled=X_labeled.reshape(-1, 32, 32, 3)\n",
    "X_val=X_val.reshape(-1, 32, 32, 3)\n",
    "X_test=X_test.reshape(-1, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iEq5WJXsGWZ"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Training the model on Downstream Task\n",
    "history=model.fit(X_labeled, y_labeled, validation_data=(X_val, y_val), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-sO-sk5QG4Y3"
   },
   "outputs": [],
   "source": [
    "#SAVE Superv MODEL\n",
    "#Source: https://machinelearningmastery.com/save-load-keras-deep-learning-models/#:~:text=The%20weights%20are%20saved%20directly,the%20symmetrical%20load_weights()%20function.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "model_name = \"supervised.h5\"\n",
    "path = f\"/content/gdrive/My Drive/A Final Project/Dev/{model_name}\"\n",
    "model.save(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBzwmXT-saYE"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on the Test set\n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8iA1QEK_UNl"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "model.save('TargetModel.h5')\n",
    "\n",
    "files.download('TargetModel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFAQrnFo5IZS"
   },
   "source": [
    "#Supervised Learning Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QPlDyyX65PKh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "#X_test = np.load('/content/drive/MyDrive/A Goldsmiths /A Final Project/DEV/Data/X_test.npy')\n",
    "#y_test = np.load('/content/drive/MyDrive/A Goldsmiths /A Final Project/DEV/Data/y_test.npy')\n",
    "\n",
    "# Print a slice of each array\n",
    "print(\"X_val:\\n\", X_val[:5])\n",
    "print(\"\\ny_val:\\n\", y_val[:5])\n",
    "\n",
    "# Training and evaluation\n",
    "\n",
    "eval_result = model.evaluate(X_val, y_val)\n",
    "print(\"\\nTest loss, Test accuracy:\", eval_result)\n",
    "\n",
    "# Visualizing the metrics\n",
    "fig, axs = plt.subplots(2)\n",
    "\n",
    "# summarize history for accuracy\n",
    "axs[0].plot(history.history['accuracy'])\n",
    "axs[0].plot(history.history['val_accuracy'])\n",
    "axs[0].set_title('Model accuracy')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "axs[1].plot(history.history['loss'])\n",
    "axs[1].plot(history.history['val_loss'])\n",
    "axs[1].set_title('Model loss')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYAr-G1iBCNb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score, recall_score, f1_score,\n",
    "                             classification_report, log_loss, roc_auc_score, roc_curve, auc)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "# Predict the classes and probabilities of the validation set\n",
    "y_val_pred = model.predict(X_val).argmax(axis=1)\n",
    "y_val_prob = model.predict(X_val)  # assuming predict gives probabilities\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Precision, Recall, F1-score with 'macro' average\n",
    "precision_macro = precision_score(y_val, y_val_pred, average='macro')\n",
    "recall_macro = recall_score(y_val, y_val_pred, average='macro')\n",
    "f1_macro = f1_score(y_val, y_val_pred, average='macro')\n",
    "\n",
    "# Precision, Recall, F1-score with 'micro' average\n",
    "precision_micro = precision_score(y_val, y_val_pred, average='micro')\n",
    "recall_micro = recall_score(y_val, y_val_pred, average='micro')\n",
    "f1_micro = f1_score(y_val, y_val_pred, average='micro')\n",
    "\n",
    "# Log Loss\n",
    "logloss = log_loss(y_val, y_val_prob)\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Macro Precision', 'Macro Recall', 'Macro F1-score',\n",
    "               'Micro Precision', 'Micro Recall', 'Micro F1-score', 'Log Loss'],\n",
    "    'Score': [accuracy, precision_macro, recall_macro, f1_macro,\n",
    "              precision_micro, recall_micro, f1_micro, logloss]\n",
    "})\n",
    "\n",
    "print(results)\n",
    "\n",
    "# ROC and AUC\n",
    "n_classes = 10\n",
    "\n",
    "# Binarize the output\n",
    "y_val_bin = label_binarize(y_val, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_val_prob[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Dkt0yZ8CS6s"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score, recall_score, f1_score,\n",
    "                             classification_report, log_loss, roc_auc_score, roc_curve, auc)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "# CIFAR-10 class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Predict the classes and probabilities of the validation set\n",
    "y_val_pred = model.predict(X_val).argmax(axis=1)\n",
    "y_val_prob = model.predict(X_val)  # assuming predict gives probabilities\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Precision, Recall, F1-score with 'macro' average\n",
    "precision_macro = precision_score(y_val, y_val_pred, average='macro')\n",
    "recall_macro = recall_score(y_val, y_val_pred, average='macro')\n",
    "f1_macro = f1_score(y_val, y_val_pred, average='macro')\n",
    "\n",
    "# Precision, Recall, F1-score with 'micro' average\n",
    "precision_micro = precision_score(y_val, y_val_pred, average='micro')\n",
    "recall_micro = recall_score(y_val, y_val_pred, average='micro')\n",
    "f1_micro = f1_score(y_val, y_val_pred, average='micro')\n",
    "\n",
    "# Log Loss\n",
    "logloss = log_loss(y_val, y_val_prob)\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Macro Precision', 'Macro Recall', 'Macro F1-score',\n",
    "               'Micro Precision', 'Micro Recall', 'Micro F1-score', 'Log Loss'],\n",
    "    'Score': [accuracy, precision_macro, recall_macro, f1_macro,\n",
    "              precision_micro, recall_micro, f1_micro, logloss]\n",
    "})\n",
    "\n",
    "print(results)\n",
    "\n",
    "# ROC and AUC\n",
    "n_classes = 10\n",
    "\n",
    "# Binarize the output\n",
    "y_val_bin = label_binarize(y_val, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_val_prob[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], class_names[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XsxKDb07rRt"
   },
   "source": [
    "##Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQH_hfDTHzDn"
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html /content/SSL_model.ipynb"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "b2Qn8VxCYosW"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
